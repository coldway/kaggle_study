# 本地运行修改说明

## 主要修改内容

### 1. 环境检测和模式选择
- 添加了 CUDA 可用性检测
- 根据环境自动选择模型加载模式：
  - 有 GPU：使用 `transformers_bf16_4bit`（量化模式）
  - 无 GPU（macOS）：使用 `transformers`（标准模式）

### 2. 禁用多 GPU 训练
- `multi_gpu_train = False`：macOS 没有多 GPU，禁用多 GPU 训练
- 所有 GPU 相关配置都添加了 `HAS_CUDA` 检查

### 3. 移除 unsloth 依赖
- 不再安装 unsloth（macOS 不支持）
- 所有 unsloth 相关代码都添加了 try-except，失败时回退到标准 transformers
- 使用标准的 `transformers` 和 `trl` 库进行训练

### 4. 安装脚本优化
- 移除了 unsloth 安装步骤
- 添加了 transformers、accelerate、bitsandbytes、datasets、trl、peft 等必要依赖
- 添加了系统信息输出

### 5. 训练参数调整
- CPU 模式：批次大小减小到 1，梯度累积增加到 4
- 优化器：CPU 模式使用 `adamw_torch`，GPU 模式使用 `adamw_8bit`
- bf16：只在有 GPU 时启用

### 6. 内存信息显示
- 添加了 CPU 模式的内存信息显示（使用 psutil）
- GPU 模式继续显示 GPU 内存信息

### 7. 模型加载
- `local_files_only=False`：允许从网络下载模型（本地运行时需要）
- 移除了对本地模型文件的硬编码依赖

## 使用方法

1. **运行安装 cell**（Cell 7）：
   - 会自动检测环境并安装必要的依赖
   - 会显示系统信息和 CUDA 状态

2. **运行训练**（Cell 8）：
   - 会自动使用适合本地环境的配置
   - macOS 会使用 CPU 模式，速度较慢但可以运行

3. **运行推理**（Cell 10）：
   - 等待训练完成后自动开始推理

4. **生成提交文件**（Cell 12）：
   - 自动生成 submission.json

## 注意事项

1. **模型访问**：
   - 如果模型是私有仓库或需要认证，需要配置 HuggingFace token：
     ```bash
     export HF_TOKEN='your_token_here'
     # 或
     huggingface-cli login
     ```
   - 如果模型已下载到本地，可以修改 `base_model` 为本地路径
   - 如果模型不可用，可以使用替代的公开模型（修改 `base_model`）
   - 详细说明请参考 `模型访问问题解决.md`

2. **模型下载**：首次运行需要从 HuggingFace 下载模型，需要网络连接
3. **运行速度**：macOS CPU 模式运行速度较慢，建议：
   - 使用较小的数据集进行测试
   - 减少训练步数
   - 使用 `arc_test_set.is_fake = True` 进行快速测试

3. **内存要求**：
   - 确保有足够的系统内存（建议 16GB+）
   - 如果内存不足，可以减小 `max_seq_length_train` 和 `max_seq_length_infer`

4. **依赖安装**：
   - 如果某些依赖安装失败，可以手动安装：
     ```bash
     pip install transformers accelerate bitsandbytes datasets trl peft psutil
     ```

## 环境要求

- Python 3.9+
- PyTorch 2.8.0+
- 足够的系统内存（16GB+ 推荐）
- 网络连接（用于下载模型）

## 故障排除

如果遇到问题：

1. **ImportError**：检查是否安装了所有依赖
2. **CUDA 错误**：确保代码使用 CPU 模式（已自动处理）
3. **内存不足**：减小批次大小或序列长度
4. **模型下载失败**：检查网络连接，或手动下载模型到本地


# 模型关系说明

## microsoft/phi-2 的作用

`microsoft/phi-2` 是**基础模型（Base Model）**，也称为**预训练模型（Pre-trained Model）**。

### 1. 基础模型的作用

- **提供通用语言理解能力**：phi-2 是微软训练的一个通用语言模型，已经在大规模文本数据上进行了预训练
- **作为微调的起点**：它提供了基础的文本生成和理解能力
- **保持模型权重**：在微调过程中，基础模型的权重通常被冻结（frozen），不会被修改

### 2. 为什么使用 phi-2？

- **公开可用**：这是一个公开的模型，可以直接从 HuggingFace 下载使用
- **适合微调**：模型大小适中（约 2.7B 参数），适合在个人机器上进行微调
- **性能良好**：在多个基准测试中表现良好

## 训练后的模型与 phi-2 的关系

### 1. 使用 LoRA 技术进行微调

从代码中可以看到，训练使用的是 **LoRA (Low-Rank Adaptation)** 技术：

```python
peft=([dict(
    r=64,  # LoRA 的秩（rank）
    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'embed_tokens', 'lm_head'],
    lora_alpha=16,
    lora_dropout=0,
    use_rslora=True,  # Rank Stabilized LoRA
)])
```

### 2. 模型结构关系

```
训练后的模型 = microsoft/phi-2 (基础模型，权重冻结)
              + LoRA 适配器 (可训练的小型权重矩阵)
```

**具体说明：**

1. **基础模型（phi-2）保持不变**
   - 所有原始权重保持冻结状态
   - 不直接修改基础模型的参数

2. **LoRA 适配器（新增的小型权重）**
   - 只训练少量参数（通常只有原模型的 0.1%-1%）
   - 通过低秩矩阵分解，在特定层（如 attention 层）添加可训练的适配器
   - 这些适配器学习如何调整基础模型的行为以适应 ARC 任务

### 3. 存储的内容

训练后保存到 `./temp/finetuned_model_gpu0/` 的内容包括：

```
finetuned_model_gpu0/
├── adapter_config.json      # LoRA 配置
├── adapter_model.bin        # LoRA 权重（只有几 MB）
└── tokenizer files          # 分词器文件
```

**注意**：保存的**不是完整的模型**，而是：
- LoRA 适配器的权重（非常小，通常只有几 MB）
- 配置信息
- 分词器文件

### 4. 推理时的加载过程

当进行推理时，代码会：

1. **加载基础模型**：从 HuggingFace 或本地加载 `microsoft/phi-2`
2. **加载 LoRA 适配器**：从 `./temp/finetuned_model_gpu0/` 加载训练好的 LoRA 权重
3. **合并使用**：将 LoRA 适配器应用到基础模型上

```python
# 推理时的加载（简化说明）
base_model = load_model("microsoft/phi-2")  # 加载基础模型
lora_weights = load_from("./temp/finetuned_model_gpu0/")  # 加载 LoRA 权重
final_model = base_model + lora_weights  # 合并使用
```

## 优势

### 1. 参数高效
- 只训练少量参数（LoRA 适配器），而不是整个模型
- 大大减少了训练时间和内存需求
- 适合在 CPU 或资源有限的 GPU 上运行

### 2. 模块化
- 基础模型和适配器分离
- 可以轻松切换不同的基础模型
- 可以为不同任务训练不同的适配器

### 3. 可移植性
- LoRA 权重文件很小，易于分享和部署
- 不需要重新下载完整的基础模型

## 完整流程示例

```
1. 初始化阶段
   └─> 加载 microsoft/phi-2 (基础模型，约 5GB)
   └─> 添加 LoRA 适配器结构（新增约几 MB 的可训练参数）

2. 训练阶段
   └─> 冻结基础模型权重（phi-2 的权重不变）
   └─> 只训练 LoRA 适配器权重
   └─> 在 ARC 数据集上进行微调

3. 保存阶段
   └─> 保存 LoRA 适配器权重（adapter_model.bin，约几 MB）
   └─> 保存配置信息（adapter_config.json）
   └─> 不保存基础模型（因为可以从 HuggingFace 重新下载）

4. 推理阶段
   └─> 重新加载 microsoft/phi-2（或使用缓存）
   └─> 加载训练好的 LoRA 适配器
   └─> 合并使用进行推理
```

## 总结

- **microsoft/phi-2**：提供通用语言能力的基础模型，权重在训练时被冻结
- **训练后的模型**：phi-2 + 针对 ARC 任务优化的 LoRA 适配器
- **关系**：训练后的模型是在 phi-2 基础上的**增量改进**，而不是完全独立的模型
- **存储**：只保存 LoRA 适配器（几 MB），不保存完整模型（几 GB）

这种方法的优势是既利用了大型预训练模型的能力，又通过少量参数的高效微调适应了特定任务。


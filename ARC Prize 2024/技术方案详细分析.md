# ARC Prize 2024 技术方案详细分析

## 🎯 解决的问题

### ARC (Abstraction and Reasoning Corpus) 挑战

**问题本质**：ARC 是一个**抽象推理任务**，要求模型从少量示例中学习模式，并应用到新的输入上。

**具体任务**：
- **输入**：几个训练示例（每个示例包含输入网格和对应的输出网格）
- **输出**：对新的测试输入网格，预测其输出网格

**挑战性**：
1. **少样本学习**：只有 1-5 个训练示例
2. **抽象推理**：需要理解抽象的模式和规则
3. **泛化能力**：模式可能涉及颜色、形状、位置、变换等多种概念
4. **组合性**：多个简单规则可能组合成复杂模式

**示例**：
```
训练示例1:
输入: [[0,1,0],    输出: [[1,0,1],
      [1,0,1],           [0,1,0],
      [0,1,0]]           [1,0,1]]
模式: 颜色反转 (0→1, 1→0)

训练示例2:
输入: [[1,1],      输出: [[2,2],
      [1,1]]             [2,2]]
模式: 所有值加1

测试输入: [[0,0,0],
          [0,0,0]]
预期输出: [[1,1,1],
          [1,1,1]]
```

## 🏗️ 解决方案架构

该方案使用**大型语言模型（LLM）**来解决 ARC 挑战，核心思路是：
1. 将网格任务转换为文本格式
2. 使用微调后的 LLM 生成候选答案
3. 通过评分算法选择最佳答案

## 📋 完整流程步骤

### 阶段 1: 数据准备与格式化

#### 步骤 1.1: 数据加载
**代码位置**：`ArcDataset.from_file()`

**做了什么**：
- 从 JSON 文件加载 ARC 挑战数据
- 解析任务结构（train examples, test inputs）
- 检测是否为测试集（通过 MD5 哈希）

**使用的技术**：
- JSON 解析
- 哈希验证（MD5）

**数据格式**：
```json
{
  "task_id": {
    "train": [
      {"input": [[0,1],[1,0]], "output": [[1,0],[0,1]]},
      ...
    ],
    "test": [
      {"input": [[0,0],[0,0]]},
      ...
    ]
  }
}
```

#### 步骤 1.2: 数据格式化（Grid → Text）
**代码位置**：`ArcFormatter` 类

**做了什么**：
- 将二维网格转换为文本字符串
- 添加特殊标记（如 `I` 表示输入，`O` 表示输出）
- 格式化训练示例和测试输入

**使用的技术**：
- 文本编码
- 特殊标记（Special Tokens）

**格式化示例**：
```
原始网格: [[0,1],[1,0]]
格式化后:
"I
0 1
1 0
O
1 0
0 1
"
```

**关键格式化策略**：
- `ArcFormatter_premix_3`: 混合格式，包含多个训练示例
- 支持不同的格式化策略（pretext2, pretext3, premix_2, premix_3）

#### 步骤 1.3: 数据增强（Data Augmentation）
**代码位置**：`ArcDataset.augment()`

**做了什么**：
- **转置（Transpose）**：`tp=True` - 交换行和列
- **旋转（Rotation）**：`rot=True` - 90度旋转（最多3次）
- **排列（Permutation）**：`perm='rnd_all'` - 随机排列训练示例顺序
- **打乱示例**：`shfl_ex=True` - 打乱训练示例内部顺序
- **打乱键**：`shfl_keys=True` - 打乱任务键的顺序

**使用的技术**：
- 几何变换（NumPy）
- 随机排列
- 数据增强策略

**为什么需要数据增强**：
1. **增加训练数据量**：从少量示例生成更多变体
2. **提高泛化能力**：模型学习到不变的模式
3. **鲁棒性**：对输入变换不敏感

**示例**：
```python
原始任务 → 转置 → 旋转90° → 排列 → 增强后的多个变体
```

### 阶段 2: 模型准备

#### 步骤 2.1: 基础模型加载
**代码位置**：`prepare_model()`

**做了什么**：
- 从 HuggingFace 加载预训练模型（如 `microsoft/phi-2`）
- 加载对应的分词器（Tokenizer）
- 根据环境选择加载模式（CPU/GPU，量化/非量化）

**使用的技术**：
- HuggingFace Transformers
- 模型量化（4-bit, BF16）
- 设备映射（Device Mapping）

**加载模式**：
- `transformers`: 标准模式（CPU）
- `transformers_bf16_4bit`: 量化模式（GPU，节省内存）

#### 步骤 2.2: LoRA 适配器配置
**代码位置**：`prepare_model()` 中的 `peft` 参数

**做了什么**：
- 在基础模型上添加 LoRA（Low-Rank Adaptation）适配器
- 配置 LoRA 参数（rank, alpha, dropout等）
- 指定目标模块（attention 层、MLP 层等）

**使用的技术**：
- **PEFT (Parameter-Efficient Fine-Tuning)**
- **LoRA (Low-Rank Adaptation)**
- **Rank Stabilized LoRA (RS-LoRA)**

**LoRA 配置**：
```python
{
    'r': 64,  # 秩（rank），控制适配器大小
    'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', ...],
    'lora_alpha': 16,  # 缩放因子
    'lora_dropout': 0,  # Dropout（0 表示不使用）
    'use_rslora': True,  # 使用 Rank Stabilized LoRA
}
```

**为什么使用 LoRA**：
- 只训练少量参数（原模型的 0.1%-1%）
- 大幅减少内存和计算需求
- 保持基础模型的通用能力

#### 步骤 2.3: 嵌入层优化（可选）
**代码位置**：`shrink_embeddings()`

**做了什么**：
- 缩小词汇表大小，只保留实际使用的 token
- 减少模型嵌入层的参数量
- 节省内存

**使用的技术**：
- 词汇表裁剪
- BPE（Byte Pair Encoding）合并处理

### 阶段 3: 模型训练

#### 步骤 3.1: 训练数据准备
**代码位置**：`prepare_dataset()` (train=True)

**做了什么**：
- 移除答案（`remove_replies()`）- 训练时不需要答案
- 应用数据增强（`augment()`）
- 截断到最大长度（`cut_to_len()`）
- 按长度排序（可选）

**使用的技术**：
- 数据增强管道
- 序列长度管理

#### 步骤 3.2: 训练执行
**代码位置**：`training_run()`

**做了什么**：
- 使用 SFT (Supervised Fine-Tuning) 训练器
- 在增强后的数据上训练 LoRA 适配器
- 使用梯度累积和检查点节省内存
- 保存训练好的模型

**使用的技术**：
- **TRL (Transformer Reinforcement Learning)** 库
- **SFTTrainer** - 监督微调训练器
- **梯度累积** - 模拟更大的批次
- **梯度检查点** - 节省内存
- **学习率调度** - Cosine 调度器

**训练参数**：
```python
{
    'per_device_train_batch_size': 1-2,  # 批次大小
    'gradient_accumulation_steps': 4,    # 梯度累积
    'learning_rate': 1e-4,               # 学习率
    'num_train_epochs': 1,                # 训练轮数
    'warmup_steps': 100,                  # 预热步数
    'optim': 'adamw_torch',               # 优化器
}
```

**训练目标**：
- 让模型学会从输入-输出示例中学习模式
- 生成符合 ARC 格式的输出网格

### 阶段 4: 推理（Inference）

#### 步骤 4.1: 推理数据准备
**代码位置**：`prepare_dataset()` (train=False)

**做了什么**：
- 分割多答案任务（`split_multi_replies()`）
- 应用数据增强（生成多个变体）
- 交错原始和增强数据（`interleave()`）
- 截断到推理最大长度

**使用的技术**：
- 数据增强（推理时）
- 任务分割

#### 步骤 4.2: 生成候选答案
**代码位置**：`inference_run_v2()`, `inference_step()`

**做了什么**：
- 对每个测试输入，使用模型生成多个候选答案
- 支持多种生成策略：
  - **标准生成**：使用 `model.generate()`
  - **Turbo DFS**：深度优先搜索，基于概率剪枝

**使用的技术**：
- **自回归生成** - 逐 token 生成
- **Beam Search**（如果支持）
- **Turbo DFS** - 自定义搜索算法
- **概率剪枝** - 基于概率阈值过滤候选

**Turbo DFS 算法**：
```python
def turbo_dfs(model, logits, ...):
    # 1. 计算每个 token 的负对数似然（NLL）
    # 2. 按概率排序
    # 3. 深度优先搜索，剪枝低概率路径
    # 4. 返回多个候选答案及其分数
```

**为什么使用 Turbo DFS**：
- 生成多个候选答案
- 基于概率选择最有希望的路径
- 比标准生成更灵活

#### 步骤 4.3: 解码与验证
**代码位置**：`Decoder.process()`, `formatter.decode_to_array()`

**做了什么**：
- 将生成的 token 序列解码回网格格式
- 验证输出格式是否正确
- 计算每个答案的分数

**使用的技术**：
- Token 解码
- 格式验证
- 分数计算

### 阶段 5: 答案选择与评分

#### 步骤 5.1: 增强评分（Augmented Scoring）
**代码位置**：`Decoder.calc_augmented_scores()`

**做了什么**：
- 对每个候选答案，应用数据增强
- 使用增强后的数据重新评分
- 计算多个增强变体的平均分数

**使用的技术**：
- 数据增强（评分时）
- 多视图评分
- 分数聚合

**为什么需要增强评分**：
- 提高答案选择的鲁棒性
- 通过多个视角验证答案质量
- 减少对特定变换的敏感性

#### 步骤 5.2: 答案选择算法
**代码位置**：`selection.py` 中的各种选择函数

**做了什么**：
- 从多个候选答案中选择最佳答案
- 使用不同的评分策略：
  - `score_all_probsum`: 基于概率和
  - `score_full_probmul_3`: 基于概率乘积（带增强）

**使用的技术**：
- 概率聚合
- 多候选排序
- 选择策略

**选择策略示例**：
```python
def score_full_probmul_3(guesses):
    # 1. 对每个候选答案计算概率乘积
    # 2. 考虑增强分数
    # 3. 选择概率最高的答案
    return best_guess
```

#### 步骤 5.3: 生成提交文件
**代码位置**：`arc_test_set.get_submission()`

**做了什么**：
- 将选定的答案格式化为提交格式
- 每个任务提供 2 个候选答案（attempt_1, attempt_2）
- 保存为 JSON 文件

**提交格式**：
```json
{
  "task_id": [
    {
      "attempt_1": [[1,0],[0,1]],
      "attempt_2": [[0,1],[1,0]]
    }
  ]
}
```

## 🔧 核心技术总结

### 1. 参数高效微调（PEFT）
- **LoRA**: 低秩适配，只训练少量参数
- **RS-LoRA**: Rank Stabilized LoRA，更稳定的训练

### 2. 数据增强
- **几何变换**: 转置、旋转
- **排列增强**: 示例顺序打乱
- **多视图**: 从不同角度观察同一任务

### 3. 推理策略
- **Turbo DFS**: 深度优先搜索 + 概率剪枝
- **多候选生成**: 生成多个答案后选择最佳
- **增强评分**: 通过数据增强验证答案质量

### 4. 模型优化
- **量化**: 4-bit 量化减少内存
- **梯度检查点**: 节省训练内存
- **嵌入层裁剪**: 减少词汇表大小

### 5. 格式化策略
- **多种格式化方法**: pretext2, pretext3, premix_2, premix_3
- **特殊标记**: 清晰区分输入/输出
- **序列化**: 将网格转换为文本

## 📊 完整流程图

```
1. 数据加载
   └─> JSON 解析
   └─> ArcDataset 创建

2. 数据格式化
   └─> 网格 → 文本
   └─> 添加特殊标记
   └─> ArcFormatter

3. 数据增强（训练时）
   └─> 转置、旋转、排列
   └─> 生成多个变体

4. 模型准备
   └─> 加载基础模型（phi-2）
   └─> 添加 LoRA 适配器
   └─> 配置训练参数

5. 模型训练
   └─> SFT 训练
   └─> 训练 LoRA 适配器
   └─> 保存模型

6. 推理数据准备
   └─> 分割任务
   └─> 应用增强
   └─> 交错数据

7. 生成候选答案
   └─> Turbo DFS / 标准生成
   └─> 多个候选答案

8. 解码与验证
   └─> Token → 网格
   └─> 格式验证

9. 增强评分
   └─> 应用增强
   └─> 重新评分
   └─> 分数聚合

10. 答案选择
    └─> 评分算法
    └─> 选择最佳答案

11. 生成提交
    └─> 格式化
    └─> 保存 JSON
```

## 🎓 关键创新点

1. **将视觉任务转换为文本任务**：通过格式化将网格转换为文本，利用 LLM 的强大能力

2. **数据增强的广泛应用**：不仅在训练时增强，还在推理和评分时使用

3. **多候选答案策略**：生成多个候选，通过评分选择最佳

4. **增强评分机制**：通过数据增强验证答案的鲁棒性

5. **参数高效微调**：使用 LoRA 在资源有限的情况下实现有效训练

## 📈 性能优化

- **内存优化**：量化、梯度检查点、嵌入层裁剪
- **计算优化**：LoRA、批次大小调整、梯度累积
- **数据优化**：数据增强、长度截断、排序策略

这个方案在 ARC Prize 2024 竞赛中获得了 **53.5 分**（私有测试集），展现了将 LLM 应用于抽象推理任务的有效性。


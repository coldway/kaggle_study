# ARC Prize 2024 解决方案代码结构分析

## 📋 整体架构

这是一个用于解决 ARC (Abstraction and Reasoning Corpus) 挑战的深度学习解决方案，使用了大型语言模型（LLM）进行训练和推理。

## 🗂️ 文件结构

### 1. **核心模块文件**（由 notebook 生成）

#### `model_runner.py` - 模型运行核心
**功能**：模型加载、训练、推理的核心函数

**主要函数**：
- `prepare_model()`: 准备和配置模型（加载、量化、LoRA等）
- `training_run()`: 执行模型训练
- `inference_run_v2()`: 执行推理任务
- `inference_turbo_dfs()`: 使用深度优先搜索进行推理
- `shrink_embeddings()`: 缩小模型嵌入层以节省内存
- `merge_peft_into_base()`: 将 LoRA 权重合并到基础模型

**关键概念**：
- **Unsloth**: 用于高效训练 LLM 的库
- **LoRA (Low-Rank Adaptation)**: 参数高效微调技术
- **4-bit 量化**: 减少模型内存占用

#### `arc_loader.py` - 数据加载器
**功能**：加载和处理 ARC 挑战数据

**主要类**：
- `ArcDataset`: ARC 数据集类
  - `from_file()`: 从 JSON 文件加载数据
  - `augment()`: 数据增强（旋转、转置、排列等）
  - `split_multi_replies()`: 处理多个答案
  - `cut_to_len()`: 截断到指定长度

- `ArcFormatter`: 数据格式化器
  - 将 ARC 任务转换为模型可理解的文本格式
  - 处理输入/输出格式
  - 支持多种格式化策略（pretext2, pretext3, premix_2, premix_3）

**数据格式**：
- 输入：网格（grid）形式的任务描述
- 输出：目标网格

#### `selection.py` - 答案选择算法
**功能**：从多个候选答案中选择最佳答案

**主要函数**：
- `score_all_probsum()`: 基于概率和评分
- `score_full_probmul_3()`: 基于概率乘积评分（带增强）
- `make_unique()`: 去除重复答案
- `get_best_shape_by_score()`: 按形状和分数选择最佳答案

**选择策略**：
1. `first_only`: 只返回第一个答案
2. `keep_order`: 保持顺序返回所有答案
3. `keep_order_unique`: 保持顺序但去重
4. `score_all_probsum`: 基于概率和
5. `score_full_probmul_3`: 基于概率乘积（推荐）

#### `async_tools.py` - 异步工具
**功能**：处理异步子进程（在 Kaggle 环境中使用）

**主要函数**：
- `wait_for_subprocess()`: 等待单个子进程
- `wait_for_subprocesses()`: 等待多个子进程

**注意**：在本地环境中，这些函数可能不适用，因为 `%%python --bg` 是 Kaggle 特定的。

#### `common_stuff.py` - 通用配置
**功能**：配置和主执行逻辑

**主要配置**：
```python
# 路径配置
tmp_dir = './temp'
arc_challenge_file = './arc-prize-2024/arc-agi_test_challenges.json'
arc_solutions_file = './arc-prize-2024/arc-agi_training_solutions.json'

# 模型配置
base_model = 'wb55l_nemomini_fulleval'  # Hugging Face 模型名
MyFormatter = ArcFormatter_premix_3  # 数据格式化器

# 训练配置
train_epochs = 4
multi_gpu_train = True  # 是否使用多 GPU
max_seq_length_train = 4224  # 训练序列长度
max_seq_length_infer = 8192  # 推理序列长度
```

**主要函数**：
- `prepare_run()`: 准备模型和格式化器
- `prepare_dataset()`: 准备训练/推理数据集
- `start_training()`: 启动训练过程
- `start_inference()`: 启动推理过程

## 🔄 执行流程

### 训练流程
1. **加载数据** → `ArcDataset.from_file()`
2. **数据增强** → `augment()` (旋转、转置、排列)
3. **准备模型** → `prepare_model()` (加载基础模型 + LoRA)
4. **训练** → `training_run()` (使用 Unsloth Trainer)
5. **保存模型** → 保存到 `./temp/finetuned_model_gpu{0,1}`

### 推理流程
1. **等待训练完成** → 检查 `{model_path}_done` 文件
2. **加载训练好的模型** → `prepare_run(storage_path)`
3. **准备推理数据** → `prepare_dataset(train=False)`
4. **执行推理** → `inference_run_v2()` (生成候选答案)
5. **增强评分** → `calc_augmented_scores()` (对答案进行变换和评分)
6. **选择最佳答案** → `submission_select_algo()` (使用评分算法)
7. **生成提交文件** → `submission.json`

## 🎯 关键概念解释

### 1. **数据增强 (Data Augmentation)**
- **旋转 (rot)**: 90度、180度、270度旋转
- **转置 (tp)**: 矩阵转置
- **排列 (perm)**: 随机排列网格元素
- **打乱示例 (shfl_ex)**: 打乱训练示例顺序

### 2. **模型配置**
- **Unsloth 4-bit**: 使用 4-bit 量化减少内存
- **LoRA**: 只训练少量参数（r=64, alpha=16）
- **目标模块**: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj

### 3. **推理策略**
- **Turbo DFS**: 使用深度优先搜索生成多个候选答案
- **最小概率阈值**: `min_prob=0.17` 过滤低概率答案
- **多猜测**: `n_guesses=2` 每个任务生成2个候选答案

### 4. **评分机制**
- **推理分数**: 模型生成答案的对数概率
- **增强分数**: 对答案进行变换后的平均分数
- **最终分数**: `inf_score + aug_score`

## 📊 Notebook 单元格结构

### Cell 0-1: 版权和说明
- 版权信息
- 竞赛说明

### Cell 2: 生成 `model_runner.py`
- 导出模型运行相关函数

### Cell 3: 生成 `arc_loader.py`
- 导出数据加载器

### Cell 4: 生成 `selection.py`
- 导出选择算法

### Cell 5: 生成 `async_tools.py`
- 导出异步工具

### Cell 6: 生成 `common_stuff.py`
- 导出配置和主函数

### Cell 7: 安装依赖和初始化
- 安装 numpy, tqdm, tokenizers
- 安装 unsloth
- 导入 common_stuff
- 清理临时文件

### Cell 8-11: 启动训练和推理进程
**注意**：这些单元格使用 `%%python --bg` 魔法命令，在本地环境中不工作。

- Cell 8: `start_training(gpu=0)` - GPU 0 训练
- Cell 9: `start_training(gpu=1)` - GPU 1 训练
- Cell 10: `start_inference(gpu=0)` - GPU 0 推理
- Cell 11: `start_inference(gpu=1)` - GPU 1 推理

### Cell 12: 等待所有进程完成
- 使用 `wait_for_subprocesses()` 等待所有进程

### Cell 13+: 生成提交文件
- 选择最佳答案
- 生成 `submission.json`

## ⚠️ 本地运行注意事项

### 问题 1: `%%python --bg` 不支持
**原因**：这是 Kaggle 特定的魔法命令，本地 Jupyter 不支持。

**解决方案**：见下面的"本地运行替代方案"。

### 问题 2: 多 GPU 支持
**注意**：如果只有单 GPU，需要修改 `multi_gpu_train = False`

### 问题 3: 内存限制
**建议**：
- 减少 `max_seq_length_train` 和 `max_seq_length_infer`
- 减少 `per_device_train_batch_size`
- 使用更小的模型

## 🔧 本地运行替代方案

由于 `%%python --bg` 在本地不工作，需要修改执行方式。见 `本地运行方案.md`。


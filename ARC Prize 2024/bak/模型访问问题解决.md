# 模型访问问题解决方案

## 问题描述

如果遇到以下错误：
```
OSError: wb55l_nemomini_fulleval is not a local folder and is not a valid model identifier
HTTPError: 401 Client Error: Unauthorized
```

这表示模型需要认证或模型不存在。

## 解决方案

### 方案 1: 配置 HuggingFace Token（推荐）

如果模型是私有仓库或需要认证：

1. **获取 HuggingFace Token**：
   - 访问 https://huggingface.co/settings/tokens
   - 创建新的 token（选择 "Read" 权限）

2. **配置 Token**（选择一种方式）：

   **方式 A: 使用环境变量**
   ```bash
   export HF_TOKEN='your_token_here'
   ```
   
   **方式 B: 使用 HuggingFace CLI**
   ```bash
   huggingface-cli login
   ```
   然后输入你的 token

   **方式 C: 在 Jupyter Notebook 中设置**
   ```python
   import os
   os.environ['HF_TOKEN'] = 'your_token_here'
   ```

### 方案 2: 使用本地模型路径

如果模型已经下载到本地：

1. 修改 `common_stuff.py` 中的 `base_model`：
   ```python
   base_model = '/path/to/your/local/model'  # 本地模型路径
   ```

2. 确保路径正确，例如：
   ```python
   base_model = './models/wb55l_nemomini_fulleval'
   # 或
   base_model = '~/models/wb55l_nemomini_fulleval'
   ```

### 方案 3: 使用替代的公开模型

如果原始模型不可用，可以使用其他模型进行测试：

修改 `common_stuff.py` 中的 `base_model`：

```python
# 选项 1: 使用较小的公开模型（用于测试）
base_model = 'microsoft/phi-2'  # 2.7B 参数，公开可用

# 选项 2: 使用 Llama 2（需要申请访问）
base_model = 'meta-llama/Llama-2-7b-hf'  # 需要先申请访问权限

# 选项 3: 使用其他公开模型
base_model = 'mistralai/Mistral-7B-v0.1'  # 需要 token
base_model = 'google/gemma-2b'  # 需要 token
```

**注意**：使用不同的模型可能需要调整训练参数。

### 方案 4: 检查模型是否存在

1. 访问 https://huggingface.co/wb55l_nemomini_fulleval
2. 检查模型是否存在
3. 如果不存在，可能需要：
   - 联系模型作者获取访问权限
   - 使用替代模型
   - 从其他来源获取模型文件

## 验证配置

运行以下代码检查配置：

```python
import os
from common_stuff import base_model

print(f"Model: {base_model}")
print(f"Is local path: {os.path.exists(base_model) if isinstance(base_model, str) else False}")
print(f"HF_TOKEN configured: {bool(os.environ.get('HF_TOKEN') or os.environ.get('HUGGINGFACE_TOKEN'))}")
```

## 常见问题

### Q: 如何知道模型是否需要 token？
A: 访问模型的 HuggingFace 页面，如果显示 "Private" 或需要 "Request access"，则需要 token。

### Q: Token 应该放在哪里？
A: 推荐使用环境变量 `HF_TOKEN`，这样更安全且不会泄露到代码中。

### Q: 可以使用其他模型吗？
A: 可以，但需要注意：
- 模型架构可能不同
- 可能需要调整训练参数
- 性能可能不同

### Q: 如何下载模型到本地？
A: 使用以下命令：
```bash
huggingface-cli download wb55l_nemomini_fulleval --local-dir ./models/wb55l_nemomini_fulleval
```

## 快速修复步骤

1. **设置 token**（如果模型需要认证）：
   ```bash
   export HF_TOKEN='your_token'
   ```

2. **或者修改为本地路径**（如果模型已下载）：
   编辑 `common_stuff.py`，修改 `base_model` 为本地路径

3. **或者使用替代模型**：
   编辑 `common_stuff.py`，修改 `base_model` 为公开模型名称

4. **重新运行 notebook**

